{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of project_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPafW53SmbPazuSvJFdUIel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theolht/NLP_Project/blob/main/NLP_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRZsh90qzORs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bbf113-b6f5-474d-e764-91bbd4d8e162"
      },
      "source": [
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.lancaster import LancasterStemmer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import SimpleRNN\r\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np \r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9uX8iyVvPLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4ec4e4-fb8b-4c4b-e474-0dc7f5f02519"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4UmFBmzynCS"
      },
      "source": [
        "df = pd.read_csv (r'gdrive/MyDrive/NLP_Project/training.1600000.processed.noemoticon.csv', encoding='latin-1')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVqxsehEKlmn"
      },
      "source": [
        "Just keeping the important data. The comment and the comment sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUAdLQG3oxw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7dfa55e8-8373-413f-feba-edf8ac460f69"
      },
      "source": [
        "data = df.copy()\r\n",
        "data.columns = ['target', 'id_tweet', 'date', 'flag', 'user', 'comment']\r\n",
        "del data['flag']\r\n",
        "del data['id_tweet']\r\n",
        "del data['date']\r\n",
        "del data['user']\r\n",
        "\r\n",
        "data = data.sample(frac = 1)\r\n",
        "data = data.head(100000)\r\n",
        "data"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>969687</th>\n",
              "      <td>4</td>\n",
              "      <td>lol  I think I might be spoiled.  How about if...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081789</th>\n",
              "      <td>4</td>\n",
              "      <td>finishing packing for trip to College Station ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043259</th>\n",
              "      <td>4</td>\n",
              "      <td>Hey guys, I won't be using my Globe phone from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322271</th>\n",
              "      <td>0</td>\n",
              "      <td>Damn my computer is officially done for.  how ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109953</th>\n",
              "      <td>4</td>\n",
              "      <td>startin my day with a run around Boone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218319</th>\n",
              "      <td>4</td>\n",
              "      <td>@EASTBAYTRIBE thanks babe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483730</th>\n",
              "      <td>4</td>\n",
              "      <td>Raffa is coming over tonight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345628</th>\n",
              "      <td>4</td>\n",
              "      <td>@bravesgirl5 8:45am is early?.. in highschool ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509390</th>\n",
              "      <td>0</td>\n",
              "      <td>Missin' Superman...Gotta wait another week...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1272292</th>\n",
              "      <td>4</td>\n",
              "      <td>@annettekelley You are a strange, strange woma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target                                            comment\n",
              "969687        4  lol  I think I might be spoiled.  How about if...\n",
              "1081789       4  finishing packing for trip to College Station ...\n",
              "1043259       4  Hey guys, I won't be using my Globe phone from...\n",
              "322271        0  Damn my computer is officially done for.  how ...\n",
              "1109953       4            startin my day with a run around Boone \n",
              "...         ...                                                ...\n",
              "1218319       4                         @EASTBAYTRIBE thanks babe \n",
              "1483730       4                      Raffa is coming over tonight \n",
              "1345628       4  @bravesgirl5 8:45am is early?.. in highschool ...\n",
              "509390        0     Missin' Superman...Gotta wait another week... \n",
              "1272292       4  @annettekelley You are a strange, strange woma...\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIM7j43qKwjT"
      },
      "source": [
        "Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBcKqExO7SEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c03ceed-059b-4c6e-d48e-4ddf03bac3c5"
      },
      "source": [
        "stemmer = LancasterStemmer()\r\n",
        "\r\n",
        "for id, comment in data['comment'].items():\r\n",
        "  comment = nltk.word_tokenize(comment)\r\n",
        "  comment = [ ch.lower() for ch in comment if ch.isalpha() or ch == '.']\r\n",
        "  comment = [w for w in comment if not w in list(nltk.corpus.stopwords.words('english'))]\r\n",
        "  comment = [stemmer.stem(w) for w in comment]\r\n",
        "  data['comment'][id] = comment"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdbMmzayKzBx"
      },
      "source": [
        "Changing the comment sentiment from 4 to 1 for easier utilization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqu0i_JD2nbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "02739b9f-f359-427e-b6ca-103f5b3ec9f2"
      },
      "source": [
        "data['target'][data['target']==4]=1\r\n",
        "data"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>969687</th>\n",
              "      <td>1</td>\n",
              "      <td>[lol, think, might, spoil, ., giv, today, prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081789</th>\n",
              "      <td>1</td>\n",
              "      <td>[fin, pack, trip, colleg, stat, weekend, danie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1043259</th>\n",
              "      <td>1</td>\n",
              "      <td>[hey, guy, wo, us, glob, phon, today, til, sun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322271</th>\n",
              "      <td>0</td>\n",
              "      <td>[damn, comput, off, don, ., im, fin, mixtap]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109953</th>\n",
              "      <td>1</td>\n",
              "      <td>[startin, day, run, around, boon]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218319</th>\n",
              "      <td>1</td>\n",
              "      <td>[eastbaytrib, thank, bab]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1483730</th>\n",
              "      <td>1</td>\n",
              "      <td>[raff, com, tonight]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345628</th>\n",
              "      <td>1</td>\n",
              "      <td>[ear, highschool, class, start, hah]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509390</th>\n",
              "      <td>0</td>\n",
              "      <td>[missin, superm, got, ta, wait, anoth, week]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1272292</th>\n",
              "      <td>1</td>\n",
              "      <td>[annettekelley, strange, strange, wom, ., good...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         target                                            comment\n",
              "969687        1  [lol, think, might, spoil, ., giv, today, prom...\n",
              "1081789       1  [fin, pack, trip, colleg, stat, weekend, danie...\n",
              "1043259       1  [hey, guy, wo, us, glob, phon, today, til, sun...\n",
              "322271        0       [damn, comput, off, don, ., im, fin, mixtap]\n",
              "1109953       1                  [startin, day, run, around, boon]\n",
              "...         ...                                                ...\n",
              "1218319       1                          [eastbaytrib, thank, bab]\n",
              "1483730       1                               [raff, com, tonight]\n",
              "1345628       1               [ear, highschool, class, start, hah]\n",
              "509390        0       [missin, superm, got, ta, wait, anoth, week]\n",
              "1272292       1  [annettekelley, strange, strange, wom, ., good...\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UnB5dqSLAx_"
      },
      "source": [
        "RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEZUeuio_3H"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(SimpleRNN(128, input_shape=(51,1)))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb_8AQRBurpE"
      },
      "source": [
        "X = data.comment\r\n",
        "y = data.target\r\n",
        "\r\n",
        "max = 500   # length max\r\n",
        "tok = Tokenizer(num_words=2000)\r\n",
        "tok.fit_on_texts(X)\r\n",
        "\r\n",
        "sequences = tok.texts_to_sequences(X)\r\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max)\r\n",
        "\r\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(sequences_matrix, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeizLO4Mute6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33a4e1b-4195-4ed3-9334-eda9e7b1f41f"
      },
      "source": [
        "Xtest = np.expand_dims(Xtest, axis=2)\r\n",
        "loss,acc = model.evaluate(Xtest, ytest)\r\n",
        "\r\n",
        "print(\"loss: %.2f\" % (loss))\r\n",
        "print(\"accuracy: %.2f\" % (acc))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 51, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 51, 1), dtype=tf.float32, name='simple_rnn_5_input'), name='simple_rnn_5_input', description=\"created by layer 'simple_rnn_5_input'\"), but it was called on an input with incompatible shape (32, 500, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 51, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 51, 1), dtype=tf.float32, name='simple_rnn_5_input'), name='simple_rnn_5_input', description=\"created by layer 'simple_rnn_5_input'\"), but it was called on an input with incompatible shape (32, 500, 1).\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.8070 - accuracy: 0.5028\n",
            "loss: 0.81\n",
            "accuracy: 0.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3L0xFheIK7-"
      },
      "source": [
        "Xtrain = np.expand_dims(Xtrain, axis=2)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDWYwumhJXC9",
        "outputId": "6a30b75f-4259-4049-ca97-017b8cddea2c"
      },
      "source": [
        "model.fit(Xtrain,ytrain, epochs=5)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 51, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 51, 1), dtype=tf.float32, name='simple_rnn_4_input'), name='simple_rnn_4_input', description=\"created by layer 'simple_rnn_4_input'\"), but it was called on an input with incompatible shape (32, 500, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 51, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 51, 1), dtype=tf.float32, name='simple_rnn_4_input'), name='simple_rnn_4_input', description=\"created by layer 'simple_rnn_4_input'\"), but it was called on an input with incompatible shape (32, 500, 1).\n",
            "2500/2500 [==============================] - 249s 99ms/step - loss: 0.6970 - accuracy: 0.5132\n",
            "Epoch 2/5\n",
            "2500/2500 [==============================] - 249s 100ms/step - loss: 0.6945 - accuracy: 0.5135\n",
            "Epoch 3/5\n",
            "2500/2500 [==============================] - 249s 100ms/step - loss: 0.6940 - accuracy: 0.5170\n",
            "Epoch 4/5\n",
            "2500/2500 [==============================] - 249s 100ms/step - loss: 0.6935 - accuracy: 0.5172\n",
            "Epoch 5/5\n",
            "2500/2500 [==============================] - 249s 99ms/step - loss: 0.6935 - accuracy: 0.5178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efca7dfa690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpZP99FmLECD"
      },
      "source": [
        "We can see that we have really bad accuracy lets try something else"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc02bTjdKjvU"
      },
      "source": [
        "inputs = Input(name='inputs',shape=[max])\r\n",
        "layer = Embedding(2000,50,input_length=max)(inputs)\r\n",
        "layer = LSTM(64)(layer)\r\n",
        "layer = Dense(256,name='FC1')(layer)\r\n",
        "layer = Activation('relu')(layer)\r\n",
        "layer = Dropout(0.5)(layer)\r\n",
        "layer = Dense(1,name='out_layer')(layer)\r\n",
        "layer = Activation('sigmoid')(layer)\r\n",
        "model2 = Model(inputs=inputs,outputs=layer)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qgP8AM1U7j3"
      },
      "source": [
        "model2.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AklDBHLU9zP",
        "outputId": "5a820524-4ec1-4dcb-df39-98d08c6129f9"
      },
      "source": [
        "history = model2.fit(Xtrain, ytrain, batch_size=80, epochs=6, validation_split=0.1)\r\n",
        "print(\"End\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "900/900 [==============================] - 309s 342ms/step - loss: 0.5730 - accuracy: 0.6908 - val_loss: 0.5534 - val_accuracy: 0.7103\n",
            "Epoch 2/6\n",
            "900/900 [==============================] - 307s 341ms/step - loss: 0.4977 - accuracy: 0.7588 - val_loss: 0.5128 - val_accuracy: 0.7470\n",
            "Epoch 3/6\n",
            "900/900 [==============================] - 306s 340ms/step - loss: 0.4955 - accuracy: 0.7585 - val_loss: 0.5078 - val_accuracy: 0.7508\n",
            "Epoch 4/6\n",
            "900/900 [==============================] - 307s 341ms/step - loss: 0.4757 - accuracy: 0.7716 - val_loss: 0.5139 - val_accuracy: 0.7496\n",
            "Epoch 5/6\n",
            "900/900 [==============================] - 306s 340ms/step - loss: 0.4723 - accuracy: 0.7736 - val_loss: 0.5128 - val_accuracy: 0.7531\n",
            "Epoch 6/6\n",
            "900/900 [==============================] - 307s 342ms/step - loss: 0.4632 - accuracy: 0.7800 - val_loss: 0.5122 - val_accuracy: 0.7514\n",
            "End\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htUI-BYgU_-J",
        "outputId": "9220c314-da44-4fbb-eba5-1fbffa425855"
      },
      "source": [
        "accuracy = model2.evaluate(Xtest,ytest)\r\n",
        "print('Test set\\n  Accuracy: {:0.2f}'.format(accuracy[1]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 34s 55ms/step - loss: 0.4979 - accuracy: 0.7569\n",
            "Test set\n",
            "  Accuracy: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}